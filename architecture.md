# UI generation architecture
For a UI generation system, we want to leverage LLMs/VLMs to create user interfaces. The architecture can be broken down into several key components: 
1. **End Device**: This is the device where the user interacts with the UI. It could be a web browser, mobile app, Hololens, etc. The end device will render the UI generated by the system. It has to be capable of displaying a pre-defined set of UI components (e.g., buttons, text fields, images, etc.) and handle user interactions (e.g., clicks, swipes, voice commands, etc.).
2. **UI Generator**: This system is responsible to generate the UI definition based on the user input and context. It will use LLMs/VLMs to understand the user's intent and generate a UI layout accordingly. The UI generator will output a structured representation of the UI (e.g., JSON, XML, etc.) that can be interpreted by the end device.
3. **External Thing**: This component represents any external system or service that the UI needs to interact with. This could be a light switch, a database, an API, etc. The UI generator may need to query or send data to these external things to create a meaningful UI.
4. **Communication Layer**: This layer handles the communication between the end device, UI generator, and external things. It ensures that the UI definition is sent to the end device and that any interactions from the user are sent back to the UI generator or external things as needed.
5. **Context Manager**: This component maintains the context of the user session. It keeps track of the user's preferences, previous interactions, and any relevant data that can help the UI generator create a more personalized UI.