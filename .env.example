# Environment template for docker-compose
# Copy or rename this file to `.env` before running `docker compose up`

# Local fallback LLM endpoint (used when OpenRouter is disabled/unavailable)
LLM_ENDPOINT=http://192.168.1.73:1234/v1/chat/completions
# Default model name for both local and OpenRouter requests
LLM_MODEL=gemma 3b

# --- Optional OpenRouter configuration ---
# Supply your API key to enable OpenRouter as the primary provider.
OPENROUTER_API_KEY=
# Override the OpenRouter REST endpoint if needed.
OPENROUTER_API_URL=https://openrouter.ai/api/v1/chat/completions
# Preferred OpenRouter model identifier (falls back to LLM_MODEL if blank).
OPENROUTER_MODEL=
# (Optional) Public URL of this app for OpenRouter telemetry headers.
OPENROUTER_APP_URL=
# (Optional) Human-friendly name shown in OpenRouter dashboards.
OPENROUTER_APP_NAME=IMP Requirements KB
# (Optional) Reasoning effort hint accepted by reasoning-capable OpenRouter models (e.g., low|medium|high).
OPENROUTER_REASONING_EFFORT=
